"""
This document about technical details about Web Scraping,
it will be used building freelance project catalogs like ğŸ–ï¸:
	â¡ï¸ "DATA SCRAPING"
	â¡ï¸ "SCRIPT"
	â¡ï¸ "DESKTOP APPLICATION"
	â¡ï¸ "WEB APPLICATION"
"""


â¬œï¸ What is the goal of this documentâ“ï¸
This document will be used inherit web scraping component on different project catalogs.





â¬œï¸ How do identify web scraping design patternâ“ï¸
	ğŸ‘‰ï¸ Check website type (static or dynamic) with "Disable JavaScript"
	ğŸ‘‰ï¸ Find out "Hidden API" if any thing out there with chrome developer "network" tab
	ğŸ‘‰ï¸ Identify bot detect technology behind website with "Wappalyzer"
	ğŸ‘‰ï¸ View captcha result with website testing tools ("https://tools.pingdom.com/", "https://gtmetrix.com/", "https://tools.keycdn.com/speed")
	ğŸ‘‰ï¸ Find out project pattern combine (optional)
	ğŸ‘‰ï¸ Write down pattern type of "Design Document"
	
	â¡ï¸ List of web scraping design pattern we have:
		â™Šï¸ Static Website
		â™Šï¸ Hidden API
		â™Šï¸ Simple Dynamic Website
		â™Šï¸ Hard Dynamic Website with Playwright
		â™Šï¸ Headless 3rd party API
		â™Šï¸ Combination of Multiple Pattern
		
	

	

â¬œï¸ What are steps about building Scrapy projectâ“ï¸
Scrapy spider building steps, and components:
	ğŸ‘‰ï¸ Make sure you have "Design Document" 
	ğŸ‘‰ï¸ Project
	ğŸ‘‰ï¸ Spider
	ğŸ‘‰ï¸ Define models on items.py file
	ğŸ‘‰ï¸ Write minimal spider code with out pagination
	ğŸ‘‰ï¸ Do data cleaning task on pipelines.py file
	ğŸ‘‰ï¸ Do Scrapy project extensions work like integrating database, proxy, or other related task
	ğŸ‘‰ï¸ Define important settings and logs
	ğŸ‘‰ï¸ Write pagination code
	ğŸ‘‰ï¸ Test spider and foreword next software development task
	
	â¡ï¸ List of steps about writing Scrapy framework components
		ğŸ‘‰ï¸ Define project and spider name
			â™Šï¸ project_name
			â™Šï¸ spider_name
		ğŸ‘‰ï¸ Define start request process; like general Scrapy request, reading urls from file, or format string
			â™Šï¸ start_url_description
		ğŸ‘‰ï¸ Define parse method key points
			â™Šï¸ parse_method_key_points
		ğŸ‘‰ï¸ Define data extraction method key points
			â™Šï¸ data_extraction_method_key_points
		ğŸ‘‰ï¸ Define pagination
			â™Šï¸ pagination__key_point
		ğŸ‘‰ï¸ Define key settings about project
			â™Šï¸ settings_key_point
		ğŸ‘‰ï¸ Define proxy or other type of integration
			â™Šï¸ scrapy_integration
		ğŸ‘‰ï¸ Work with Scrapy logs
			â™Šï¸ logs_setup



	
	
â¬œï¸ What about STATIC_WEBSITE design componentâ“ï¸
Steps about collecting Static Website design components:
	ğŸ‘‰ï¸ Define Scrapy project component
	ğŸ‘‰ï¸ Write down proxy integration plan
	ğŸ‘‰ï¸ Select spider running machine
		â™Šï¸ spider_running_machine
	
	â¡ï¸ Common milestone task:
		â™Šï¸ Write XPATH code on Jupyter lab
		â™Šï¸ Build project based on Scrapy steps
	






â¬œï¸ What about HIDDEN_API design componentâ“ï¸
Steps about collecting Static Website design components:
	ğŸ‘‰ï¸ Identify API URL on Google chrome console
	ğŸ‘‰ï¸ Work with pagination URL on Insomnia
	ğŸ‘‰ï¸ Work with cookies and data validation
	ğŸ‘‰ï¸ Write data extraction code on Jupyter lab
	ğŸ‘‰ï¸ Define Scrapy project component
	ğŸ‘‰ï¸ Write down proxy integration plan
	ğŸ‘‰ï¸ Select spider running machine
		â™Šï¸ spider_running_machine

	â¡ï¸ Common milestone task:
		â™Šï¸ Build pagination project on Insomnia		
		â™Šï¸ Write data extraction code on Jupyter lab
		â™Šï¸ Build project based on Scrapy steps
		
		


â¬œï¸ What about SIMPLE_DYNAMIC_WEBSITE design componentâ“ï¸
Steps about collecting simple dynamic website design components:
	ğŸ‘‰ï¸ Brain storm about target website find easy navigation
	ğŸ‘‰ï¸ Write Playwright automation code on Python file
	ğŸ‘‰ï¸ Write Scrapy-Playwright settings key points
	ğŸ‘‰ï¸ Define Scrapy project component
	ğŸ‘‰ï¸ Select spider running machine
	
	â¡ï¸ Common milestone task:
		â™Šï¸ Write website automation code on Jupyter lab
		â™Šï¸ Write data extraction code on Jupyter lab
		â™Šï¸ Build project based on Scrapy steps
		â™Šï¸ Integrate Scrapy-Playwright with Scrapy project
	



